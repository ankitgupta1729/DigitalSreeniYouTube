{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaYGfm4exEEk4TBvgg4QPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/321_what_is_particle_swarm_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/FRXsQ6qbJbs"
      ],
      "metadata": {
        "id": "fovSYXS4QJcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Particle Swarm Optimization** <p>\n",
        "PSO is a swarm intelligence algorithm that is inspired by the behavior of social organisms such as flocks of birds or schools of fish.\n",
        "<p>\n",
        "The algorithm creates a population of particles, each representing a candidate solution, that move through the search space based on their individual velocity and the collective influence of the best solutions found by the swarm.\n",
        "<p>\n",
        "The algorithm updates the particles' positions and velocities based on the fitness of the current solution and the local and global best solutions found so far. It aims to balance exploration and exploitation by encouraging particles to explore new regions of the search space while also following promising solutions.\n",
        "<p>\n",
        "PSO is suitable for solving nonlinear and dynamic optimization problems, such as in control systems, machine learning, and signal processing.\n",
        "<p>\n",
        "PSO has been used for feature selection, image segmentation, and classification in microscopy images. For example, it has been used to optimize the parameters of texture descriptors for image segmentation, and to select the most discriminative features for cell classification."
      ],
      "metadata": {
        "id": "6fmf6W-ov-xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define the objective function\n",
        "def objective_function(params):\n",
        "    x, y, z = params[0], params[1], params[2]\n",
        "    return (x-4)**2 + (y-5)**2 + (z+6)**2\n",
        "\n",
        "# Define the bounds of the search space\n",
        "bounds = np.array([[-10, -10, -10], [10, 10, 10]])\n",
        "\n",
        "# Define the parameters of the optimization that control the movement of the\n",
        "# particles in the search space.\n",
        "n_particles = 10\n",
        "max_iterations = 30\n",
        "\n",
        "w = 0.5 #the inertia weight that balances the particle's current velocity\n",
        "#high value of w leads to more exploration and less exploitation\n",
        "\n",
        "#c1 and c2 are the acceleration coefficients that control the influence of the\n",
        "# particle's best personal position and the global best position on its movement.\n",
        "c1 = 0.8  #Cognitive component - represents the particle's tendency to move towards its best personal position\n",
        "c2 = 0.9  #Social component, which represents the particle's tendency to move towards the global best position found by the swarm\n",
        "\n",
        "# Initialize the particles and velocities\n",
        "particles = np.random.uniform(low=bounds[0], high=bounds[1], size=(n_particles, 3))\n",
        "velocities = np.zeros((n_particles, 3))\n",
        "\n",
        "# Initialize the best positions and best costs\n",
        "best_positions = particles.copy()\n",
        "best_costs = np.array([objective_function(p) for p in particles])\n",
        "\n",
        "# Initialize the global best position and global best cost\n",
        "global_best_position = particles[0].copy()\n",
        "global_best_cost = best_costs[0]\n",
        "\n",
        "# Perform the optimization\n",
        "for i in range(max_iterations):\n",
        "    # Update the velocities\n",
        "    r1 = np.random.rand(n_particles, 3) #Random matrix used to compute the cognitive component of the veocity update\n",
        "    r2 = np.random.rand(n_particles, 3) #Random matrix used to compute the social component of the veocity update\n",
        "\n",
        "\n",
        "    #Cognitive component is calculated by taking the difference between the\n",
        "    #particle's current position and its best personal position found so far,\n",
        "    #and then multiplying it by a random matrix r1 and a cognitive acceleration coefficient c1.\n",
        "    cognitive_component = c1 * r1 * (best_positions - particles)\n",
        "\n",
        "    #The social component represents the particle's tendency to move towards the\n",
        "    #global best position found by the swarm. It is calculated by taking the\n",
        "    #difference between the particle's current position and the global best position\n",
        "    # found by the swarm, and then multiplying it by a random matrix r2 and a\n",
        "    #social acceleration coefficient c2.\n",
        "    social_component = c2 * r2 * (global_best_position - particles)\n",
        "\n",
        "    #The new velocity of the particle is computed by adding the current velocity\n",
        "    #to the sum of the cognitive and social components, multiplied by the inertia\n",
        "    #weight w. The new velocity is then used to update the position of the\n",
        "    #particle in the search space.\n",
        "    velocities = w * velocities + cognitive_component + social_component\n",
        "\n",
        "    # Update the particles\n",
        "    particles += velocities\n",
        "\n",
        "    # Enforce the bounds of the search space\n",
        "    particles = np.clip(particles, bounds[0], bounds[1])\n",
        "\n",
        "    # Evaluate the objective function\n",
        "    costs = np.array([objective_function(p) for p in particles])\n",
        "\n",
        "    # Update the best positions and best costs\n",
        "    is_best = costs < best_costs\n",
        "    best_positions[is_best] = particles[is_best]\n",
        "    best_costs[is_best] = costs[is_best]\n",
        "\n",
        "    # Update the global best position and global best cost\n",
        "    global_best_index = np.argmin(best_costs)\n",
        "    global_best_position = best_positions[global_best_index].copy()\n",
        "    global_best_cost = best_costs[global_best_index]\n",
        "\n",
        "    # Print the progress\n",
        "    print(f'Iteration {i+1}: Best Cost = {global_best_cost:.6f}')\n",
        "\n",
        "# Print the results\n",
        "print('Global Best Position:', global_best_position)\n",
        "print('Global Best Cost:', global_best_cost)\n"
      ],
      "metadata": {
        "id": "qLGprkABIvLH",
        "outputId": "9fed3f13-ced7-45a9-88be-9b90e1a8d099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Best Cost = 1.605089\n",
            "Iteration 2: Best Cost = 1.605089\n",
            "Iteration 3: Best Cost = 1.605089\n",
            "Iteration 4: Best Cost = 0.747548\n",
            "Iteration 5: Best Cost = 0.747548\n",
            "Iteration 6: Best Cost = 0.747548\n",
            "Iteration 7: Best Cost = 0.373921\n",
            "Iteration 8: Best Cost = 0.278859\n",
            "Iteration 9: Best Cost = 0.278859\n",
            "Iteration 10: Best Cost = 0.211723\n",
            "Iteration 11: Best Cost = 0.183925\n",
            "Iteration 12: Best Cost = 0.150164\n",
            "Iteration 13: Best Cost = 0.068172\n",
            "Iteration 14: Best Cost = 0.014235\n",
            "Iteration 15: Best Cost = 0.010780\n",
            "Iteration 16: Best Cost = 0.002296\n",
            "Iteration 17: Best Cost = 0.000744\n",
            "Iteration 18: Best Cost = 0.000433\n",
            "Iteration 19: Best Cost = 0.000370\n",
            "Iteration 20: Best Cost = 0.000084\n",
            "Iteration 21: Best Cost = 0.000084\n",
            "Iteration 22: Best Cost = 0.000039\n",
            "Iteration 23: Best Cost = 0.000039\n",
            "Iteration 24: Best Cost = 0.000039\n",
            "Iteration 25: Best Cost = 0.000032\n",
            "Iteration 26: Best Cost = 0.000032\n",
            "Iteration 27: Best Cost = 0.000002\n",
            "Iteration 28: Best Cost = 0.000001\n",
            "Iteration 29: Best Cost = 0.000001\n",
            "Iteration 30: Best Cost = 0.000000\n",
            "Global Best Position: [ 3.9997275   4.9999267  -6.00026393]\n",
            "Global Best Cost: 1.492874651607639e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why code ourselves if we can use pyswarms? <br>\n",
        "Check out the next tutorial for a ractical example using pyswarms\n"
      ],
      "metadata": {
        "id": "k0YEYofSIuAH"
      }
    }
  ]
}